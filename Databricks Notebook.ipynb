{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4388ba72-d6a6-4693-963f-ccccf5609918",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table products updated for current 2025-08-26 date\nTable sales updated for current 2025-08-26 date\nTable inventory updated for current 2025-08-26 date\nTable status updated for current 2025-08-26 date\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "base_url = \"abfss://mycontainer@adlsgen2salesdata2025.dfs.core.windows.net/salesdata\"\n",
    "\n",
    "datasets = {\n",
    "    \"products\": f\"{base_url}/Products/{today}/Products_{today}.csv\",\n",
    "    \"sales\": f\"{base_url}/Sales/{today}/Sales_{today}.csv\",\n",
    "    \"inventory\": f\"{base_url}/Inventory/{today}/Inventory_{today}.csv\",\n",
    "    \"status\": f\"{base_url}/Status/{today}/Status_{today}.csv\",\n",
    "}\n",
    "\n",
    "catalog = \"my_sales_catalog\"\n",
    "schema = \"sales_schema\"\n",
    "\n",
    "for table_name, file_path in datasets.items():\n",
    "    df = (spark.read\n",
    "            .option(\"header\", True)\n",
    "            .option(\"inferSchema\", True)\n",
    "            .csv(file_path))\n",
    "    \n",
    "    (df.write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"overwrite\")\n",
    "            .option(\"overwriteSchema\", \"true\")\n",
    "            .saveAsTable(f\"{catalog}.{schema}.{table_name}\"))\n",
    "    \n",
    "    print(f\"Table {table_name} updated for current {today} date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd69546a-5433-48e5-bbe7-c2209805f63a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DataFrame for products created.\n DataFrame for sales created.\n DataFrame for inventory created.\n DataFrame for status created.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "base_url = \"abfss://mycontainer@adlsgen2salesdata2025.dfs.core.windows.net/salesdata\"\n",
    "\n",
    "datasets = {\n",
    "    \"products\": f\"{base_url}/Products/{today}/Products_{today}.csv\",\n",
    "    \"sales\": f\"{base_url}/Sales/{today}/Sales_{today}.csv\",\n",
    "    \"inventory\": f\"{base_url}/Inventory/{today}/Inventory_{today}.csv\",\n",
    "    \"status\": f\"{base_url}/Status/{today}/Status_{today}.csv\",\n",
    "\n",
    "}\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "for table_name, file_path in datasets.items():\n",
    "    df = (spark.read\n",
    "            .option(\"header\", True)\n",
    "            .option(\"inferSchema\", True)\n",
    "            .csv(file_path))\n",
    "\n",
    "    dataframes[f\"{table_name}_df\"] = df\n",
    "\n",
    "    print(f\" DataFrame for {table_name} created.\")\n",
    "\n",
    "products_df = dataframes['products_df']\n",
    "sales_df = dataframes['sales_df']\n",
    "inventory_df = dataframes['inventory_df']\n",
    "status_df = dataframes['status_df']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ba05af3-f5b1-4e11-9464-8dfa10f4eba0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------+-------+-------+--------+-------+-------------------+------+\n|OrderID|FirstName|LastName|Country|Product|Quantity|  Price|          Timestamp|Status|\n+-------+---------+--------+-------+-------+--------+-------+-------------------+------+\n|   1001|Charlotte|  Lorenz|    USA|      1|       2|  41.33|2025-08-20 15:06:36|     2|\n|   1002|   Olivia|  Garcia| Canada|      6|       3| 198.88|2025-08-20 21:55:00|     2|\n|   1003|     Noah|Williams| Mexico|      8|       1|1027.44|2025-08-20 06:15:38|     2|\n|   1004| Isabella|  Miller|Germany|      6|       4| 655.33|2025-08-20 07:40:00|     3|\n|   1005|    Corey|  Miller| Canada|      8|       1| 970.68|2025-08-20 00:15:11|     1|\n|   1006|     Alex|   Lopez|    USA|      3|       3| 781.07|2025-08-20 03:32:48|     3|\n|   1007|      Ian|  Garcia|Austria|      8|       3| 437.76|2025-08-20 00:18:56|     1|\n|   1008|    James|   Smith|  Spain|      4|       2| 820.53|2025-08-20 15:41:30|     2|\n+-------+---------+--------+-------+-------+--------+-------+-------------------+------+\nonly showing top 8 rows\n"
     ]
    }
   ],
   "source": [
    "sales_df.show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08964a14-cb45-4c90-b8e4-cf5894b18dcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------+-------+-------+--------+-------+----------+------+\n|OrderID|FirstName|LastName|Country|Product|Quantity|  Price|      Date|Status|\n+-------+---------+--------+-------+-------+--------+-------+----------+------+\n|   1001|Charlotte|  Lorenz|    USA|      1|       2|  41.33|2025-08-20|     2|\n|   1002|   Olivia|  Garcia| Canada|      6|       3| 198.88|2025-08-20|     2|\n|   1003|     Noah|Williams| Mexico|      8|       1|1027.44|2025-08-20|     2|\n|   1004| Isabella|  Miller|Germany|      6|       4| 655.33|2025-08-20|     3|\n|   1005|    Corey|  Miller| Canada|      8|       1| 970.68|2025-08-20|     1|\n|   1006|     Alex|   Lopez|    USA|      3|       3| 781.07|2025-08-20|     3|\n|   1007|      Ian|  Garcia|Austria|      8|       3| 437.76|2025-08-20|     1|\n|   1008|    James|   Smith|  Spain|      4|       2| 820.53|2025-08-20|     2|\n+-------+---------+--------+-------+-------+--------+-------+----------+------+\nonly showing top 8 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, to_date\n",
    "sales_df = sales_df.withColumn(\"timestamp\", to_date(col(\"timestamp\"), \"yyyy-MM-dd\"))\n",
    "sales_df = sales_df.withColumnRenamed(\"Timestamp\", \"Date\")\n",
    "sales_df.show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cdb1a58-d5ad-4c5f-be64-880741ad08f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[OrderID: int, FirstName: string, LastName: string, Country: string, Product: int, Quantity: int, Price: double, Date: date, Status: int]\nDataFrame[ProductID: int, ProductName: string]\nDataFrame[ProductID: int, InStock: int, Sold: string, UpdatedStock: string]\nDataFrame[StatusID: int, Status: string]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+display_df_hint": {
       "mode": "should_hint",
       "name": "status_df",
       "type": "pyspark.sql.connect.dataframe.DataFrame"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(sales_df)\n",
    "print(products_df)\n",
    "print(inventory_df)\n",
    "print(status_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a9ac16f-e5b8-4f30-bee1-1cd397e0ed62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------+-------+--------+-----------+-------+----------+---------+\n|OrderID|FirstName|LastName|Country|Quantity|ProductName|  Price|      Date|   Status|\n+-------+---------+--------+-------+--------+-----------+-------+----------+---------+\n|   1001|Charlotte|  Lorenz|    USA|       2|     Laptop|  41.33|2025-08-20|  Shipped|\n|   1002|   Olivia|  Garcia| Canada|       3|         TV| 198.88|2025-08-20|  Shipped|\n|   1003|     Noah|Williams| Mexico|       1|    Charger|1027.44|2025-08-20|  Shipped|\n|   1004| Isabella|  Miller|Germany|       4|         TV| 655.33|2025-08-20|Delivered|\n|   1005|    Corey|  Miller| Canada|       1|    Charger| 970.68|2025-08-20|     Open|\n|   1006|     Alex|   Lopez|    USA|       3|   Keyboard| 781.07|2025-08-20|Delivered|\n|   1007|      Ian|  Garcia|Austria|       3|    Charger| 437.76|2025-08-20|     Open|\n|   1008|    James|   Smith|  Spain|       2|    Monitor| 820.53|2025-08-20|  Shipped|\n+-------+---------+--------+-------+--------+-----------+-------+----------+---------+\nonly showing top 8 rows\n"
     ]
    }
   ],
   "source": [
    "s = sales_df.alias(\"s\")\n",
    "p = products_df.alias(\"p\")\n",
    "st = status_df.alias(\"st\")\n",
    "\n",
    "joined_sales_df = (s.join(p, s.Product == p.ProductID)\n",
    "                  .join(st, s.Status == st.StatusID))\n",
    "\n",
    "joined_sales_df=joined_sales_df.select(\"s.OrderID\", \"s.FirstName\", \"s.LastName\", \"s.Country\", \"s.Quantity\", \"p.ProductName\", \"s.Price\", \"s.Date\", \"st.Status\")\n",
    "\n",
    "joined_sales_df.show(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8175a062-d16d-458b-bb4a-d02a55728fdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+\n|Status|TotalOpenOrders|\n+------+---------------+\n|  Open|             76|\n+------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "open_orders_df = joined_sales_df.filter(col(\"Status\") == \"Open\")\n",
    "\n",
    "\n",
    "open_orders_df = open_orders_df.groupby(\"Status\").agg(count(\"Status\").alias(\"TotalOpenOrders\"))\n",
    "\n",
    "open_orders_df.show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fda1353-f0a8-4e1e-9856-5d0ea54bc812",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-------------+\n|Product|NumberofSales|TotalQuantity|\n+-------+-------------+-------------+\n|      1|           43|          106|\n|      4|           31|           79|\n|      8|           50|          119|\n|      6|           31|           84|\n|      3|           30|           70|\n|      2|           39|           87|\n|      7|           27|           70|\n|      5|           28|           59|\n+-------+-------------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, sum\n",
    "sales_summary = sales_df.groupBy(\"Product\").agg(count(\"Quantity\").alias(\"NumberofSales\"),(sum(\"quantity\").alias(\"TotalQuantity\")))\n",
    "sales_summary.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14383671-8c29-48ac-a1a5-eab4cd79a29e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-------+-----------+------------+\n|Product|TotalQuantity|InStock|ProductName|UpdatedStock|\n+-------+-------------+-------+-----------+------------+\n|      1|          106|   1000|     Laptop|         894|\n|      2|           87|   1000|      Mouse|         913|\n|      3|           70|   1000|   Keyboard|         930|\n|      4|           79|   1000|    Monitor|         921|\n|      5|           59|   1000|     Webcam|         941|\n|      6|           84|   1000|         TV|         916|\n|      7|           70|   1000|    Speaker|         930|\n|      8|          119|   1000|    Charger|         881|\n+-------+-------------+-------+-----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "ss = sales_summary.alias(\"ss\")\n",
    "p = products_df.alias(\"p\")\n",
    "i = inventory_df.alias(\"i\")\n",
    "\n",
    "upd_inv_df = (ss.join(i, ss.Product == i.ProductID, \"inner\")\n",
    "              .join(p, ss.Product == p.ProductID, \"inner\"))\n",
    "\n",
    "upd_inv_df = upd_inv_df.select(\"ss.Product\", \"ss.TotalQuantity\", \"i.InStock\", \"p.ProductName\")\n",
    "upd_inv_df = upd_inv_df.withColumn(\"UpdatedStock\", col(\"InStock\") - col(\"TotalQuantity\"))\n",
    "upd_inv_df = upd_inv_df.orderBy(\"Product\")\n",
    "upd_inv_df.show(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e573a1a5-91fe-4140-8852-b3ec78f1c2d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "joined_sales_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"my_sales_catalog.sales_schema.joined_sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a81a191-1a1f-4a06-8b46-1ecaf202700e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "joined_sales_df.write.mode(\"append\").parquet(\"abfss://mycontainer@adlsgen2salesdata2025.dfs.core.windows.net/salesdata/cleaned/sales_summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aeb09d5-4054-446c-8b7f-eb5a22e7061a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "upd_inv_df.write.option(\"header\", \"true\").mode(\"overwrite\").csv(\"abfss://mycontainer@adlsgen2salesdata2025.dfs.core.windows.net/salesdata/cleaned/inventory\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-08-25 17:42:41",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}